{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "\n",
    "# Commonly used modules\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# import cv2\n",
    "import IPython\n",
    "# from six.moves import urllib\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# reshape images to specify that it's a single channel\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(imgs): # should work for both a single image and multiple images\n",
    "    sample_img = imgs if len(imgs.shape) == 2 else imgs[0]\n",
    "    assert sample_img.shape in [(28, 28, 1), (28, 28)], sample_img.shape # make sure images are 28x28 and single-channel (grayscale)\n",
    "    return imgs / 255.0\n",
    "\n",
    "train_images = preprocess_images(train_images)\n",
    "test_images = preprocess_images(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.xlabel(train_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# 32 convolution filters used each of size 3x3\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# 64 convolution filters used each of size 3x3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# randomly turn neurons on and off to improve convergence\n",
    "model.add(Dropout(0.25))\n",
    "# flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "# fully connected to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# one more dropout\n",
    "model.add(Dropout(0.5))\n",
    "# output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.Adam(), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 134s 71ms/step - loss: 0.2021 - accuracy: 0.9382\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 133s 71ms/step - loss: 0.0843 - accuracy: 0.9747\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 116s 62ms/step - loss: 0.0625 - accuracy: 0.9814\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 120s 64ms/step - loss: 0.0532 - accuracy: 0.9838\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 120s 64ms/step - loss: 0.0451 - accuracy: 0.9861\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmelnyk2\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\image_utils.py:409: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 266ms/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.models import load_model\n",
    " \n",
    "# load and prepare the image\n",
    "def load_image(filename):\n",
    " # load the image\n",
    " img = load_img(filename, grayscale=True, target_size=(28, 28))\n",
    " # convert to array\n",
    " img = img_to_array(img)\n",
    " # reshape into a single sample with 1 channel\n",
    " img = img.reshape(1, 28, 28, 1)\n",
    " # prepare pixel data\n",
    " img = img.astype('float32')\n",
    " img = img / 255.0\n",
    " return img\n",
    " \n",
    "# load an image and predict the class\n",
    "def run_example():\n",
    " # load the image\n",
    " img = load_image('img.png')\n",
    " # predict the class\n",
    " predict_value = model.predict(img)\n",
    " digit = argmax(predict_value)\n",
    " print(digit)\n",
    " \n",
    "# entry point, run the example\n",
    "run_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
